<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>人格检测_用户画像</title>
    <url>/2021/07/25/%E4%BA%BA%E6%A0%BC%E6%A3%80%E6%B5%8B_%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/</url>
    <content><![CDATA[<h1 id="用户画像"><a href="#用户画像" class="headerlink" title="用户画像"></a>用户画像</h1><ul>
<li><p>芝麻信用分的评估</p>
</li>
<li><p>用户信息标签化，商业分析</p>
</li>
<li><p>用户属性的标签化框架</p>
</li>
<li><p><em>Patch Dictionary</em></p>
</li>
<li><p><em>Meta Learning</em></p>
<span id="more"></span>

<p><img src="/images/%E4%BA%BA%E6%A0%BC%E6%A3%80%E6%B5%8B_%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/1.png" alt="1"></p>
</li>
</ul>
<h1 id="人格检测"><a href="#人格检测" class="headerlink" title="人格检测"></a>人格检测</h1><h2 id="1-基于数据驱动的研究"><a href="#1-基于数据驱动的研究" class="headerlink" title="1. 基于数据驱动的研究"></a>1. 基于数据驱动的研究</h2><p><img src="/images/%E4%BA%BA%E6%A0%BC%E6%A3%80%E6%B5%8B_%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/2.png" alt="2"></p>
<ul>
<li>用户人格识别中，样本量小和分布失衡的问题研究(<em>Tomek Link</em>方法)</li>
</ul>
<h2 id="2-基于应用驱动的模型"><a href="#2-基于应用驱动的模型" class="headerlink" title="2. 基于应用驱动的模型"></a>2. 基于应用驱动的模型</h2><p><img src="/images/%E4%BA%BA%E6%A0%BC%E6%A3%80%E6%B5%8B_%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/3.png" alt="3"></p>
<p><img src="/images/%E4%BA%BA%E6%A0%BC%E6%A3%80%E6%B5%8B_%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/4.png" alt="4"></p>
]]></content>
      <tags>
        <tag>CPSS</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown学习笔记</title>
    <url>/2021/07/25/Markdown%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="Markdown学习笔记"><a href="#Markdown学习笔记" class="headerlink" title="Markdown学习笔记"></a>Markdown学习笔记</h1><span id="more"></span>

<h2 id="1-标题写法"><a href="#1-标题写法" class="headerlink" title="1.标题写法"></a>1.标题写法</h2><p>前置加“ # ”，一级标题加一个，二级标题加两个，依此类推…（注意不要忽略掉“ # ”后面的空格）</p>
<h2 id="2-字体"><a href="#2-字体" class="headerlink" title="2.字体"></a>2.字体</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">*斜体文本*</span><br><span class="line">**粗体文本**</span><br><span class="line">***粗斜体文本***</span><br></pre></td></tr></table></figure>

<h2 id="3-分割线"><a href="#3-分割线" class="headerlink" title="3.分割线"></a>3.分割线</h2><p>连续的三个以上的“ * ”或“ - ”</p>
<h2 id="4-下划线"><a href="#4-下划线" class="headerlink" title="4.下划线"></a>4.下划线</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;u&gt;带下划线文本&lt;/u&gt;</span><br></pre></td></tr></table></figure>

<h2 id="5-脚注"><a href="#5-脚注" class="headerlink" title="5.脚注"></a>5.脚注</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[^要注明的文本]</span><br></pre></td></tr></table></figure>

<p>后注与前注有所不同</p>
<h2 id="6-代码框"><a href="#6-代码框" class="headerlink" title="6.代码框"></a>6.代码框</h2><ul>
<li><p>连续三个“ ~ ”</p>
</li>
<li><p>对于单个代码框可以“ ~ ”…” ~ “链接</p>
</li>
</ul>
<h2 id="7-区块"><a href="#7-区块" class="headerlink" title="7.区块"></a>7.区块</h2><p>​    “ &gt;  “+文字，多层嵌套的话就用多个” &gt; “</p>
<h2 id="8-链接"><a href="#8-链接" class="headerlink" title="8.链接"></a>8.链接</h2><p>这是一个链接&lt; 网址 &gt;</p>
<p>这是一个链接[链接名]（网址）</p>
]]></content>
      <tags>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title>LBSN专题</title>
    <url>/2021/07/25/LBSN/</url>
    <content><![CDATA[<h1 id="1-用户位置预测、兴趣点（POI-推荐"><a href="#1-用户位置预测、兴趣点（POI-推荐" class="headerlink" title="1. 用户位置预测、兴趣点（POI)推荐"></a>1. 用户位置预测、兴趣点（POI)推荐</h1><span id="more"></span>

<ul>
<li>智能城市</li>
<li>论文<br><img src="/images/LBSN/1.png" alt="1"></li>
<li>马尔科夫模型+多维特征融合</li>
<li>多维特征融合</li>
<li>多维特征融合+分类/回归</li>
<li>特征融合+矩阵分解</li>
<li>主题建模</li>
<li>图嵌入学习(<em>Graph Embedding</em>)</li>
<li>循环神经网络+注意力</li>
<li>循环神经网络+周期注意力</li>
<li>循环神经网络+上下文注意力(<em>DeepMove</em>)</li>
<li>图神经网络+注意力</li>
</ul>
<h1 id="2-拓展思路"><a href="#2-拓展思路" class="headerlink" title="2. 拓展思路"></a>2. 拓展思路</h1><ul>
<li>注意力机制应用更普遍、复杂</li>
<li>多模态数据的综合利用匮乏，尤其是对带有情感状态的文本内容挖掘不足</li>
<li>建模用户在特定时间窗口内的访问偏好有待深入</li>
</ul>
<h1 id="3-LBSN中用户位置隐私的保护"><a href="#3-LBSN中用户位置隐私的保护" class="headerlink" title="3. LBSN中用户位置隐私的保护"></a>3. LBSN中用户位置隐私的保护</h1><ul>
<li>在线保护：Cloak,Dummy,Obfuscation(Pseudo-location)</li>
<li>Cloak-K匿名<br><img src="/images/LBSN/2.png" alt="2"></li>
<li>dummy-K匿名</li>
<li>obfuscation-差分隐私(地理不可分辨性)指的是地理上相近的位置经过保护机制的模糊会产生相近的模糊位置</li>
<li>Game-based obfuscation 动态防守-攻击博弈下的模糊方法</li>
<li>基于混合隐私度量的obfuscation<br><img src="/images/LBSN/3.png" alt="3"></li>
</ul>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Attention</title>
    <url>/2021/07/25/attention/</url>
    <content><![CDATA[<h1 id="Seq2Seq模型"><a href="#Seq2Seq模型" class="headerlink" title="Seq2Seq模型"></a>Seq2Seq模型</h1><span id="more"></span>

<ul>
<li><p>输入某个序列到模型，转换为另一个序列<br><img src="/images/attention/1.png" alt="1"></p>
</li>
<li><p>编码器<br><img src="/images/attention/2.png" alt="2"></p>
</li>
<li><p>解码器<br><img src="/images/attention/3.png" alt="3"></p>
</li>
<li><p>时间序列展开</p>
</li>
</ul>
<p><img src="/images/attention/4.png" alt="4"></p>
<ul>
<li>EOC 初始输入</li>
</ul>
<h1 id="Attention机制"><a href="#Attention机制" class="headerlink" title="Attention机制"></a>Attention机制</h1><p><img src="/images/attention/5.png" alt="5"></p>
<p><img src="/images/attention/6.png" alt="6"></p>
<p><img src="/images/attention/7.png" alt="7"></p>
<p><img src="/images/attention/8.png" alt="8"></p>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>图像语义</title>
    <url>/2021/07/25/%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89/</url>
    <content><![CDATA[<h1 id="场景图自动生成-Neural-Motifs"><a href="#场景图自动生成-Neural-Motifs" class="headerlink" title="场景图自动生成(Neural Motifs)"></a>场景图自动生成(Neural Motifs)</h1><span id="more"></span>

<h1 id="scene-Graphs"><a href="#scene-Graphs" class="headerlink" title="scene Graphs"></a><em>scene Graphs</em></h1><p><img src="/images/%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89/1.png" alt="1"></p>
<ul>
<li>三维场景图(牛逼..)</li>
</ul>
<h1 id="视频场景识别"><a href="#视频场景识别" class="headerlink" title="视频场景识别"></a>视频场景识别</h1><ul>
<li>图像序列<ul>
<li>考虑全局角度的场景运动信息</li>
<li>引入光流场表示时序上的动态变化</li>
<li>使用CNN提取每一视频帧的特征，使用统计方法按位进行关键帧特征聚合，采用指标拼接，输入SVM进行分类<em>SA-CNN</em></li>
</ul>
</li>
</ul>
<h1 id="音频-听觉-场景识别"><a href="#音频-听觉-场景识别" class="headerlink" title="音频(听觉)场景识别"></a>音频(听觉)场景识别</h1><ul>
<li>CNN同时提取单声道和立体声的音频特征</li>
<li>提取梅尔频谱倒谱系数，配合隐马尔科夫模型</li>
</ul>
<h1 id="短文本场景识别"><a href="#短文本场景识别" class="headerlink" title="短文本场景识别"></a>短文本场景识别</h1><ul>
<li>朴素贝叶斯+最大熵方法</li>
<li>LSA挖掘文本语义概念与场景之间的关联关系 </li>
</ul>
<h1 id="拓展延伸"><a href="#拓展延伸" class="headerlink" title="拓展延伸"></a>拓展延伸</h1><ul>
<li><p>挑战：</p>
<ul>
<li>大规模数据场景分类，数据的海量增长及类别的不断细分，区分度越来越低，数据类型也更为复杂</li>
<li>真实场景理解，场景的理解不再是单纯的分类问题，更多的是对内容语义的理解和实时性要求</li>
</ul>
</li>
<li><p>未来：</p>
<ul>
<li>提取局部特征：目前的局部特征提取方法大多是提取不同模态的全局信息，没考虑到局部的信息，即各类语义对象</li>
<li>更复杂的模态融合：捕捉到多种模式之间更复杂的相关性</li>
</ul>
</li>
</ul>
<h1 id="视频理解"><a href="#视频理解" class="headerlink" title="视频理解"></a>视频理解</h1><ul>
<li>研究方向<ul>
<li>视频分类<ul>
<li>场景分类</li>
<li>行为识别：对视频中人物行为进行分类 <ul>
<li>稠密轨迹法<ul>
<li>稳定性高，可靠性高，速度慢，精度低</li>
</ul>
</li>
<li>双流法<ul>
<li>精度高，速度慢</li>
</ul>
</li>
<li>三维卷积(C3D,P3D)<ul>
<li>速度快，精度低于双流法</li>
</ul>
</li>
<li>LSTM+CNN<ul>
<li>速度慢，精度低</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>目标跟踪</li>
<li>视频描述<ul>
<li>传统视频描述</li>
<li>密集视频描述<ul>
<li>不足：生成的描述冗余，不连贯，主要集中在如何提高描述的准确性上，很少有研究考虑生成的描述是否足以表示视频中丰富的信息</li>
</ul>
</li>
</ul>
</li>
<li>视频问答</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>CPSS</tag>
      </tags>
  </entry>
  <entry>
    <title>感知器</title>
    <url>/2021/07/25/%E6%84%9F%E7%9F%A5%E5%99%A8/</url>
    <content><![CDATA[<h1 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h1><p>两类线性可分的模式类：$w_1$，$w_2$，设$d(X) = W^TX$,其中$W = [w_1,w_2,…,w_n,w_{n+1}]^T$,$X=[x_1,x_2,…,x_n,1]^T$,$d(X)&gt;0$.</p>
<p>感知器算法通过对已知类别的训练样本集的学习，寻找一个满足上式的权向量。</p>
<span id="more"></span>

<h1 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a>算法步骤</h1><ul>
<li>选择N个分属于$w_1$和$w_2$类的模式样本构成训练样本集<br>$${X_1,…X_N}$$<br>构成增广向量形式，并进行规范化处理。任取权向量初始值$W(1)$，开始迭代，迭代次数$k=1$。</li>
<li>用全部训练样本进行一轮迭代，计算${W^T(k)}X_i$的值，并修正权向量。<br>分两种情况更新权向量的值：<ol>
<li>若${W^T(k)}X_i \leqslant0$，分类器对第$i$个模式做了错误分类，权向量校正为$W(k+1)=W(k)+cX_i$  $c$：正的校正增量</li>
<li>若${W^T(k)}X_i&gt;0$，分类正确，权向量不变：<br>$$W(k+1)=W(k)$$</li>
</ol>
</li>
<li>分析分类结果，只要有一个错误分类，回到第二步，直至所有样本正确分类</li>
</ul>
<h1 id="算法特点"><a href="#算法特点" class="headerlink" title="算法特点"></a>算法特点</h1><p>收敛性：经过有限次迭代运算后，求出了一个使所有样本都能正确分类的$W$，则称算法是收敛的。<br>收敛条件：模式类别线性可分</p>
<h1 id="算法代码1"><a href="#算法代码1" class="headerlink" title="算法代码1"></a>算法代码1</h1><p>编写感知器算法程序，求下列模式分类的解向量</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import numpy as np </span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from mpl_toolkits.mplot3d import Axes3D</span><br><span class="line">w1 = [[0 , 0 , 0 , 1] , [1 , 0 , 0 , 1] , [1 , 0 , 1 , 1] , [1 , 1 , 0 , 1] , [0 , 0 , -1 , -1] , [0 , -1 , -1 , -1] , [0 , -1 , 0 , -1] , [-1 , -1 , -1 , -1]]</span><br><span class="line">w = [-1 , -2 , -2 , 0]</span><br><span class="line">X = [[0 , 0 , 0],</span><br><span class="line">     [1 , 0 , 0],</span><br><span class="line">     [1 , 0 , 1],</span><br><span class="line">     [1 , 1 , 0],</span><br><span class="line">     [0 , 0 , -1],</span><br><span class="line">     [0 , -1 , -1],</span><br><span class="line">     [0 , -1 , 0],</span><br><span class="line">     [-1 , -1 , -1]]</span><br><span class="line">X=np.array(X)</span><br><span class="line">flag = 0</span><br><span class="line">res = [0 , 0 , 0 , 0 , 0 , 0 , 0 , 0]</span><br><span class="line">while(flag != 8):</span><br><span class="line">    flag = 0</span><br><span class="line">    for i in range(8):</span><br><span class="line">        res[i] = w[0] * w1[i][0] + w[1] * w1[i][1] + w[2] * w1[i][2] + w[3] * w1[i][3]</span><br><span class="line">        if res[i] &lt;= 0:</span><br><span class="line">            w[0] = w[0]+w1[i][0]</span><br><span class="line">            w[1] = w[1]+w1[i][1]</span><br><span class="line">            w[2] = w[2]+w1[i][2]</span><br><span class="line">            w[3] = w[3]+w1[i][3]</span><br><span class="line">            flag = flag - 1</span><br><span class="line">        else: </span><br><span class="line">            w = w</span><br><span class="line">            flag = flag + 1</span><br><span class="line">print(w)</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(12, 8))</span><br><span class="line"># 创建 3D 坐标系</span><br><span class="line">ax = fig.gca(fc=&#x27;whitesmoke&#x27;, projection=&#x27;3d&#x27; )</span><br><span class="line">x1 = np.linspace(0, 2, 9)</span><br><span class="line">x2 = np.linspace(0, 2, 9)</span><br><span class="line">x1,x2 = np.meshgrid(x1, x2)</span><br><span class="line">x3 = (-w[3] - w[0]*x1 -w[1]*x2)/w[2]</span><br><span class="line"></span><br><span class="line">ax.plot_surface(X=x1,</span><br><span class="line">                Y=x2,</span><br><span class="line">                Z=x3,</span><br><span class="line">                color=&#x27;b&#x27;,</span><br><span class="line">                alpha=0.2</span><br><span class="line">               )</span><br><span class="line">ax.set(xlabel=&#x27;X&#x27;,</span><br><span class="line">       ylabel=&#x27;Y&#x27;,</span><br><span class="line">       zlabel=&#x27;Z&#x27;,</span><br><span class="line">       xlim=(0, 2),</span><br><span class="line">       ylim=(0, 2),</span><br><span class="line">       zlim=(0, 2),</span><br><span class="line">       xticks=np.arange(0, 2, 1),</span><br><span class="line">       yticks=np.arange(0, 2, 1),</span><br><span class="line">       zticks=np.arange(0, 2, 1)</span><br><span class="line">      )</span><br><span class="line">    </span><br><span class="line">half = int(len(X)/2)</span><br><span class="line">X[4:,:] = - X[4:,:]</span><br><span class="line">x = X[:half, 0]  </span><br><span class="line">y = X[:half, 1]  </span><br><span class="line">z = X[:half, 2]  </span><br><span class="line"># fig = plt.figure()</span><br><span class="line"># ax = Axes3D(fig)</span><br><span class="line">ax.scatter(x, y, z,c=&#x27;y&#x27;,marker=&#x27;o&#x27;)</span><br><span class="line"></span><br><span class="line">x2 = X[half:, 0]  </span><br><span class="line">y2 = X[half:, 1]  </span><br><span class="line">z2 = X[half:, 2]  </span><br><span class="line">ax.scatter(x2, y2, z2,c=&#x27;r&#x27;,marker=&#x27;x&#x27;)</span><br><span class="line">for i_x, i_y,i_z in zip(X[:,0],X[:,1],X[:,2]):</span><br><span class="line">    ax.text(i_x, i_y,i_z, &#x27;(&#123;&#125;, &#123;&#125;,&#123;&#125;)&#x27;.format(int(i_x), int(i_y),int(i_z)))</span><br><span class="line">    ax.set_zlabel(&#x27;Z&#x27;)</span><br><span class="line">    ax.set_ylabel(&#x27;Y&#x27;)</span><br><span class="line">    ax.set_xlabel(&#x27;X&#x27;)</span><br><span class="line"></span><br><span class="line">plt.show()    </span><br></pre></td></tr></table></figure>

<h1 id="算法代码2"><a href="#算法代码2" class="headerlink" title="算法代码2"></a>算法代码2</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import numpy as np </span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from mpl_toolkits.mplot3d import Axes3D  </span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    path =  &#x27;data.txt&#x27;</span><br><span class="line">    data = pd.read_csv(path, header=None, names=[&#x27;x&#x27;, &#x27;y&#x27;,&#x27;z&#x27;])</span><br><span class="line">    X = np.array(data.iloc[:,:])</span><br><span class="line"></span><br><span class="line">    X = np.column_stack((X, np.ones((len(X),1))))   </span><br><span class="line">    X[4:,:] = - X[4:,:]</span><br><span class="line">    </span><br><span class="line">    c = 1</span><br><span class="line">    w = np.array([-1,-2,-2,0])</span><br><span class="line">    flag = True</span><br><span class="line">    cnt = 0</span><br><span class="line">    while flag:</span><br><span class="line">        cnt += 1</span><br><span class="line">        flag = False</span><br><span class="line">        for x in X:</span><br><span class="line">            # print(x)</span><br><span class="line"></span><br><span class="line">            if w @ x &lt;= 0:</span><br><span class="line">                w = w + c*x</span><br><span class="line">                flag = True</span><br><span class="line">            </span><br><span class="line">    print(w)</span><br><span class="line">    print(cnt)</span><br><span class="line">    </span><br><span class="line">    fig = plt.figure(figsize=(12, 8))</span><br><span class="line">    </span><br><span class="line">    # 创建 3D 坐标系</span><br><span class="line">    ax = fig.gca(fc=&#x27;whitesmoke&#x27;,</span><br><span class="line">                projection=&#x27;3d&#x27; </span><br><span class="line">                )</span><br><span class="line"></span><br><span class="line">    x1 = np.linspace(0, 2, 9)</span><br><span class="line">    x2 = np.linspace(0, 2, 9)</span><br><span class="line">    </span><br><span class="line">    x1,x2 = np.meshgrid(x1, x2)</span><br><span class="line">    x3 = (-w[3] - w[0]*x1 -w[1]*x2)/w[2]</span><br><span class="line">    ax.plot_surface(X=x1,</span><br><span class="line">                Y=x2,</span><br><span class="line">                Z=x3,</span><br><span class="line">                color=&#x27;b&#x27;,</span><br><span class="line">                alpha=0.2</span><br><span class="line">               )</span><br><span class="line">    ax.set(xlabel=&#x27;X&#x27;,</span><br><span class="line">       ylabel=&#x27;Y&#x27;,</span><br><span class="line">       zlabel=&#x27;Z&#x27;,</span><br><span class="line">       xlim=(0, 2),</span><br><span class="line">       ylim=(0, 2),</span><br><span class="line">       zlim=(0, 2),</span><br><span class="line">       xticks=np.arange(0, 2, 1),</span><br><span class="line">       yticks=np.arange(0, 2, 1),</span><br><span class="line">       zticks=np.arange(0, 2, 1)</span><br><span class="line">      )</span><br><span class="line">    </span><br><span class="line">    half = int(len(X)/2)</span><br><span class="line">    X[4:,:] = - X[4:,:]</span><br><span class="line">    x = X[:half, 0]  </span><br><span class="line">    y = X[:half, 1]  </span><br><span class="line">    z = X[:half, 2]</span><br><span class="line">    ax.scatter(x, y, z,c=&#x27;y&#x27;,marker=&#x27;o&#x27;)</span><br><span class="line"></span><br><span class="line">    x2 = X[half:, 0]  </span><br><span class="line">    y2 = X[half:, 1]  </span><br><span class="line">    z2 = X[half:, 2]  </span><br><span class="line">    ax.scatter(x2, y2, z2,c=&#x27;r&#x27;,marker=&#x27;x&#x27;)</span><br><span class="line">    for i_x, i_y,i_z in zip(X[:,0],X[:,1],X[:,2]):</span><br><span class="line">        ax.text(i_x, i_y,i_z, &#x27;(&#123;&#125;, &#123;&#125;,&#123;&#125;)&#x27;.format(int(i_x), int(i_y),int(i_z)))</span><br><span class="line">    ax.set_zlabel(&#x27;Z&#x27;)</span><br><span class="line">    ax.set_ylabel(&#x27;Y&#x27;)</span><br><span class="line">    ax.set_xlabel(&#x27;X&#x27;)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
<h1 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h1><p>对于$M$类模式应存在$M$个判决函数：{$d_i$，$i=1,…M$}</p>
<p><em>算法主要内容</em><br>设有$M$种模式类别：$w_1$,$w_2$,…,$w_M$<br>设其权向量初值为：$W_j(1)$,$j=1,…,M$<br>训练样本为增广向量形式，但不需要规范化处理<br>第$k$次迭代时，一个属于$w_i$类的模式样本$X$被送入分类器，计算所有判别函数<br>$$d_j(k)=W_j^T(k)X,j=1,…,M$$<br>分两种情况修改权向量：</p>
<ul>
<li><p>若$d_i(k)&gt;d_j(k),\forall j\ne i;j=1,2,…,M$则权向量不变；</p>
<p>$$W_j(k+1)=W_j(k),j=1,2,…,M$$</p>
</li>
<li><p>若第$l$个权向量使$d_i(k)\leqslant d_i(k)$，则相应的权向量做调整，即:</p>
</li>
</ul>
<p>$$\left{\begin{matrix}<br>W_i(k+1)=W_i(k)+cX,\<br>Wl(k+1)=W_l(k)-cX,\<br>W_j(k+1)=W_j(k),j\ne i,l<br>\end{matrix}\right.<br>其中c为正的校正增量<br>$$</p>
]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>图像生成</title>
    <url>/2021/07/25/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/</url>
    <content><![CDATA[<h1 id="自回归模型"><a href="#自回归模型" class="headerlink" title="自回归模型"></a>自回归模型</h1><ul>
<li>直接明确的概率建模</li>
<li><em>PixelRNN</em><ul>
<li>速度慢</li>
</ul>
</li>
<li><em>PixelCNN</em><ul>
<li>利用CNN建模上下文信息</li>
<li>仍然从角落开始产生像素</li>
<li>使用Mask并行训练，但测试时仍按顺序生成</li>
</ul>
</li>
<li>优点<ul>
<li>明确计算数据似然</li>
<li>数据似然可以作为较好的度量方法</li>
</ul>
</li>
<li>缺点<ul>
<li>序列化的生成过程，速度慢</li>
<li>生成顺序如何定义</li>
<li>长距离依赖问题</li>
</ul>
</li>
</ul>
<span id="more"></span>

<h1 id="变分自编码器-VAE"><a href="#变分自编码器-VAE" class="headerlink" title="变分自编码器(VAE)"></a>变分自编码器(VAE)</h1><ul>
<li>编码器压缩数据得到隐特征</li>
<li>解码器根据隐特征还原数据</li>
<li>舍弃解码器，将编码器用去特征提取</li>
<li>disCVAE 拆分</li>
<li>优点<ul>
<li>定义了概率密度，有迹可循的生成方法</li>
<li>后验概率可以作为其他任务的特征使用</li>
<li>本质上概率图模型，易扩展</li>
</ul>
</li>
<li>缺点<ul>
<li>需要通过变分下届推断，不如自回归模型直接定义的尺度</li>
<li>利用重构损失优化，生成样本模糊</li>
</ul>
</li>
</ul>
<h1 id="GAN-生成式对抗网络"><a href="#GAN-生成式对抗网络" class="headerlink" title="GAN(生成式对抗网络)"></a>GAN(生成式对抗网络)</h1><ul>
<li>不直接对数据的概率分布建模</li>
<li>通过辨别器度量生成数据与真实数据分布的距离<br><img src="/images/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/1.png" alt="1"></li>
<li><em>CGAN</em>,<em>CGAN with Auxiliary Classifier</em>,<em>SA-GAN</em>,<em>Big-GAN</em>,<em>AttnGAN</em>,<em>Obj-GAN</em>,<em>Story-GAN</em>,<em>SeqAttnGAN</em></li>
<li>具体模型架构参考视频</li>
<li>优点<ul>
<li>博弈形式隐式地度量数据分布的距离</li>
<li>生成图像质量高</li>
</ul>
</li>
<li>缺点<ul>
<li>训练不稳定，有模态坍塌风险</li>
<li>无法推断概率</li>
</ul>
</li>
</ul>
<h1 id="评估指标·"><a href="#评估指标·" class="headerlink" title="评估指标·"></a>评估指标·</h1><p><img src="/images/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/2.png" alt="2"></p>
<ul>
<li>P(y|x)图片x的分类概率</li>
<li>P(y)分类结果的边缘概率<br><img src="/images/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/3.png" alt="3"></li>
<li>各类模型特点<br><img src="/images/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/4.png" alt="4"></li>
</ul>
<h1 id="研究方向"><a href="#研究方向" class="headerlink" title="研究方向"></a>研究方向</h1><ul>
<li>任务方面<ul>
<li>交互式图像生成</li>
<li>故事生成</li>
<li>视频生成</li>
<li>3D图像生成</li>
</ul>
</li>
<li>模型本身<ul>
<li>网络结构研究：<em>Instance Norm</em>,<em>Attentive Norm</em></li>
<li>GAN的稳定性研究</li>
<li>先验知识的引入</li>
<li>更好的信息利用方法</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>CPSS</tag>
      </tags>
  </entry>
  <entry>
    <title>标题党检测</title>
    <url>/2021/07/25/%E6%A0%87%E9%A2%98%E5%85%9A%E6%A3%80%E6%B5%8B/</url>
    <content><![CDATA[<h1 id="标题党检测"><a href="#标题党检测" class="headerlink" title="标题党检测"></a>标题党检测</h1><ul>
<li><p>静态属性</p>
<ul>
<li>标题语言特征</li>
<li>标题-正文匹配</li>
</ul>
</li>
<li><p>动态属性</p>
<ul>
<li>用户行为分析</li>
</ul>
<span id="more"></span></li>
<li><p>基于标题文本特征的方法<br><img src="/images/%E6%A0%87%E9%A2%98%E5%85%9A%E6%A3%80%E6%B5%8B/1.png" alt="1"></p>
</li>
<li><p>基于标题和正文匹配程度的方法<br><img src="/images/%E6%A0%87%E9%A2%98%E5%85%9A%E6%A3%80%E6%B5%8B/2.png" alt="2"></p>
</li>
<li><p>基于社交网站用户行为的方法<br><img src="/images/%E6%A0%87%E9%A2%98%E5%85%9A%E6%A3%80%E6%B5%8B/3.png" alt="3"></p>
</li>
<li><p>总结<br><img src="/images/%E6%A0%87%E9%A2%98%E5%85%9A%E6%A3%80%E6%B5%8B/4.png" alt="4"></p>
</li>
</ul>
]]></content>
      <tags>
        <tag>CPSS</tag>
      </tags>
  </entry>
  <entry>
    <title>信息可信性</title>
    <url>/2021/07/25/%E4%BF%A1%E6%81%AF%E5%8F%AF%E4%BF%A1%E6%80%A7/</url>
    <content><![CDATA[<h1 id="谣言检测"><a href="#谣言检测" class="headerlink" title="谣言检测"></a>谣言检测</h1><span id="more"></span>

<ul>
<li><p>相关概念<br><img src="/images/%E4%BF%A1%E6%81%AF%E5%8F%AF%E4%BF%A1%E6%80%A7/1.png" alt="1"></p>
</li>
<li><p>有监督：分类</p>
<ul>
<li>静态特征：内容特征，用户特征，其他特征</li>
<li>动态特征：序列结构建模，树结构建模</li>
</ul>
</li>
<li><p>无监督：概率图</p>
</li>
</ul>
<p><img src="/images/%E4%BF%A1%E6%81%AF%E5%8F%AF%E4%BF%A1%E6%80%A7/2.png" alt="2"></p>
<ul>
<li><p>引入Attention可以不同单词对于谣言判定的权重不同<br><img src="/images/%E4%BF%A1%E6%81%AF%E5%8F%AF%E4%BF%A1%E6%80%A7/3.png" alt="3"></p>
</li>
<li><p>序列结构上下文建模的主要问题：</p>
<ul>
<li>上下文模糊：不同推文的隐特征计算，依托的前文和后文的信息应有所区别</li>
<li>基于RNN构建：无法脱离RNN结构建模，因此存在长期依赖难以学习的问题</li>
</ul>
</li>
</ul>
<h1 id="谣言抑制"><a href="#谣言抑制" class="headerlink" title="谣言抑制"></a>谣言抑制</h1><ul>
<li><p>信息传播相关模型：线性阈值模型;传染病模型;SIS模型</p>
</li>
<li><p>社区结构：模型OPOAO，DOAM<br><img src="/images/%E4%BF%A1%E6%81%AF%E5%8F%AF%E4%BF%A1%E6%80%A7/4.png" alt="4"></p>
</li>
</ul>
<p><img src="/images/%E4%BF%A1%E6%81%AF%E5%8F%AF%E4%BF%A1%E6%80%A7/5.png" alt="5"></p>
]]></content>
      <tags>
        <tag>CPSS</tag>
      </tags>
  </entry>
  <entry>
    <title>群体画像</title>
    <url>/2021/07/25/%E7%BE%A4%E4%BD%93%E7%94%BB%E5%83%8F/</url>
    <content><![CDATA[<h1 id="人群画像"><a href="#人群画像" class="headerlink" title="人群画像"></a>人群画像</h1><span id="more"></span>

<ul>
<li><p>群体<img src="/images/%E7%BE%A4%E4%BD%93%E7%94%BB%E5%83%8F/1.png" alt="1"></p>
</li>
<li><p>社会群体和社会计算之间关联</p>
<img src="/images/%E7%BE%A4%E4%BD%93%E7%94%BB%E5%83%8F/2.png" alt="2" style="zoom:75%;"></li>
<li><p>群体发现(划分算法)</p>
<h2 id="1-Community-detection"><a href="#1-Community-detection" class="headerlink" title="1.Community detection"></a>1.Community detection</h2><h2 id="2-Social-circles"><a href="#2-Social-circles" class="headerlink" title="2.Social circles"></a>2.Social circles</h2><h2 id="3-共谋群体-聚类"><a href="#3-共谋群体-聚类" class="headerlink" title="3.共谋群体(聚类)"></a>3.共谋群体(聚类)</h2></li>
</ul>
<p><img src="/images/%E7%BE%A4%E4%BD%93%E7%94%BB%E5%83%8F/3.png" alt="3"></p>
<ul>
<li>公式表示线性回归模型</li>
</ul>
<h1 id="群体画像"><a href="#群体画像" class="headerlink" title="群体画像"></a>群体画像</h1><ul>
<li>群体画像各个维度和用户画像对应</li>
<li><em>plurality voting</em></li>
</ul>
]]></content>
      <tags>
        <tag>CPSS</tag>
      </tags>
  </entry>
  <entry>
    <title>视频取证</title>
    <url>/2021/07/25/%E8%A7%86%E9%A2%91%E5%8F%96%E8%AF%81/</url>
    <content><![CDATA[<h1 id="图像取证"><a href="#图像取证" class="headerlink" title="图像取证"></a>图像取证</h1><ul>
<li>二分类任务：是否经过修改</li>
<li>多分类任务：在上一个任务的基础上区分用何种方式进行伪造，相机识别</li>
</ul>
<span id="more"></span>

<h1 id="研究现状"><a href="#研究现状" class="headerlink" title="研究现状"></a>研究现状</h1><ul>
<li>光响应非均匀性<br><img src="/images/%E8%A7%86%E9%A2%91%E5%8F%96%E8%AF%81/1.png" alt="1"></li>
<li>隐写分析模型</li>
</ul>
<h1 id="视频造假与识别"><a href="#视频造假与识别" class="headerlink" title="视频造假与识别"></a>视频造假与识别</h1><ul>
<li><p>造假方式</p>
<ul>
<li>deepfakes 变分自编码器</li>
<li>FaceSwap</li>
<li>Face2Face</li>
<li>GAN(ProGAN,StyleGAN,CycleGAN)</li>
</ul>
</li>
<li><p>识别方式</p>
<ul>
<li>光照估计</li>
<li>几何估计</li>
<li>软生物特征模型</li>
<li>基于脸部地标的检测</li>
<li>基于CNN网络的检测</li>
<li>基于眨眼的LRCN模型</li>
<li>基于频谱的检测</li>
</ul>
</li>
<li><p>检测数据集</p>
<ul>
<li>FaceForensics++</li>
</ul>
</li>
</ul>
<h1 id="变分自编码器-VAE"><a href="#变分自编码器-VAE" class="headerlink" title="变分自编码器(VAE)"></a>变分自编码器(VAE)</h1><ul>
<li>变换法<br><img src="/images/%E8%A7%86%E9%A2%91%E5%8F%96%E8%AF%81/2.png" alt="2"></li>
<li><img src="/images/%E8%A7%86%E9%A2%91%E5%8F%96%E8%AF%81/3.png" alt="3"></li>
</ul>
]]></content>
      <tags>
        <tag>CPSS</tag>
      </tags>
  </entry>
  <entry>
    <title>跨社交网络</title>
    <url>/2021/07/25/%E8%B7%A8%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<h1 id="研究概述"><a href="#研究概述" class="headerlink" title="研究概述"></a>研究概述</h1><span id="more"></span>

<p><img src="/images/%E8%B7%A8%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C/1.png" alt="1"></p>
<ul>
<li>模型角度：<ul>
<li>监督方法(需要标签数据):<ul>
<li><em>classification techniques</em><ul>
<li>从用户属性中提取特征</li>
<li>训练分类用以预测用户身份对</li>
</ul>
</li>
<li><em>embedding techniques</em><ul>
<li>获取用户表示后进行身份关联</li>
</ul>
</li>
</ul>
</li>
<li>半监督方法(需要标签数据)<ul>
<li>在模型学习时同时考虑有标签与无标签的用户身份对</li>
</ul>
</li>
<li>无监督方法(无需标签数据)<ul>
<li>已有工作较少</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="跨网络社区发现"><a href="#跨网络社区发现" class="headerlink" title="跨网络社区发现"></a>跨网络社区发现</h1><ul>
<li>常见的社区发现方法<ul>
<li>基于贝叶斯概率图模型的主题模型</li>
<li>基于非负矩阵分解的模型</li>
</ul>
</li>
<li>深度学习，能发现高级别潜在属性，</li>
</ul>
]]></content>
      <tags>
        <tag>CPSS</tag>
      </tags>
  </entry>
  <entry>
    <title>文本分类</title>
    <url>/2021/09/12/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/</url>
    <content><![CDATA[<h1 id="文本分类"><a href="#文本分类" class="headerlink" title="文本分类"></a>文本分类</h1><h2 id="1-概念"><a href="#1-概念" class="headerlink" title="1 概念"></a>1 概念</h2><ul>
<li>用计算机对文本或其他实体按照一定的分类体系或标准进行自动分类标记</li>
</ul>
<span id="more"></span>

<h2 id="2-特征表示"><a href="#2-特征表示" class="headerlink" title="2 特征表示"></a>2 特征表示</h2><ul>
<li><p>BoW词袋模型</p>
<p>忽略了文本中的词序</p>
</li>
<li><p>TF-IDF词频-逆文档频率</p>
<p>使用词频和逆文档频率来建模文本</p>
</li>
<li><p>N-gram</p>
<p>将相邻的文字和词组信息纳入表征的词典中</p>
</li>
<li><p>One-hot热独码</p>
</li>
<li><p>Word2vec</p>
<p>使用局部上下文信息来获取词向量</p>
</li>
<li><p>Glove词向量 </p>
<p>使用局部上下文信息和全局统计特征</p>
</li>
</ul>
<h2 id="3-分类模型"><a href="#3-分类模型" class="headerlink" title="3 分类模型"></a>3 分类模型</h2><h3 id="浅层学习"><a href="#浅层学习" class="headerlink" title="浅层学习"></a>浅层学习</h3><ul>
<li>NB朴素贝叶斯；HMM</li>
<li>SVM支持向量机；TSVM</li>
<li>KNN K近邻；NWKNN</li>
<li>DT决策树</li>
<li>RF随机森林；Adaboost；HGBoost；stacking</li>
</ul>
<h3 id="深层学习"><a href="#深层学习" class="headerlink" title="深层学习"></a>深层学习</h3><ul>
<li><p>ReNN规则嵌入神经网络</p>
<ul>
<li>递归地学习文本语义和句法树结构，而不需要人为的设置人工特征，这是相较于浅层网络的一大进步。文本当中的单词被视作树的叶子节点，所有节点基于权值计入父亲节点当中，如此递归计算，最终形成整篇的文章表征，用于预测类别标签。</li>
</ul>
</li>
<li><p>MLP多层感知机</p>
<ul>
<li>Paragraph Vector的引入，由谷歌的Le和Mikolov等人提出，在CBOW语言模型的预测过程中，引入段落向量来保存段落信息，将前三个词语的词向量与段落向量取平均或拼接，送入MLP来预测下一位置的词语。</li>
</ul>
</li>
<li><p>RNN</p>
<ul>
<li><p>独特的时间序列处理方式与文本阅读方式具有一致性。该模型结构能够有效学习历史信息和位置信息，有助于解决长距离依赖问题。</p>
</li>
<li><p>LSTM</p>
</li>
</ul>
</li>
<li><p>CNN卷积神经网络</p>
<ul>
<li><strong>基于不同最小单元的模型分类：</strong>按照向量表征的最小单元，可将向量分为，字符向量、词向量、句子向量</li>
</ul>
</li>
<li><p>Attention注意力机制</p>
<ul>
<li>Q,K,V</li>
<li>捕获文本分类任务当中的长距离依赖信息</li>
</ul>
</li>
<li><p>Transformer</p>
<ul>
<li>ELMo、GPT、BERT、RoBERT、ALBERT、XLNet</li>
</ul>
</li>
<li><p>GCN图卷积网络</p>
<ul>
<li>学习句子当中的语义结构</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>CPSS</tag>
      </tags>
  </entry>
  <entry>
    <title>话题发现</title>
    <url>/2021/07/25/%E8%AF%9D%E9%A2%98%E5%8F%91%E7%8E%B0/</url>
    <content><![CDATA[<h1 id="基于概率模型的话题建模"><a href="#基于概率模型的话题建模" class="headerlink" title="基于概率模型的话题建模"></a>基于概率模型的话题建模</h1><ul>
<li>基于目标的话题建模：TTM</li>
<li>基于时间的话题建模：LLA</li>
<li>基于领域知识的话题建模：Hashtag-LDA</li>
</ul>
<span id="more"></span>

<h1 id="非概率话题模型方法"><a href="#非概率话题模型方法" class="headerlink" title="非概率话题模型方法"></a>非概率话题模型方法</h1><ul>
<li>基于文档的话题建模</li>
<li>基于特征的话题建模</li>
</ul>
<h1 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h1><ul>
<li>话题模型困惑度</li>
<li>归一化点户信息</li>
</ul>
<h1 id="拓展思路"><a href="#拓展思路" class="headerlink" title="拓展思路"></a>拓展思路</h1><ul>
<li>现有的话题建模方法主要分为基于概率话题模型和基于特征或文档的非概率话题模型</li>
<li>话题演化分析是分析话题随时间的动态演变，可在内容演化，热度演化等维度对话题进行演化分析</li>
<li>话题模型选择与预训练新技术相结合</li>
<li>但是数据集通常较为单一，没有兼顾短文本和长文本特性，未来可在模型兼容性做进一步研究</li>
<li>同时采用两种模型的方法较少，但是要注意两者存在很强的互补关系</li>
</ul>
<h1 id="社交网络中的亲历者发现"><a href="#社交网络中的亲历者发现" class="headerlink" title="社交网络中的亲历者发现"></a>社交网络中的亲历者发现</h1><ul>
<li><p>位置估计</p>
<ul>
<li>基于统计机器学习的亲历者发现<ul>
<li>基于位置估计的方法<br><img src="/images/%E8%AF%9D%E9%A2%98%E5%8F%91%E7%8E%B0/1.png" alt="1"></li>
<li>不符合实际情况，人为划定时空范围，干预过多</li>
<li>基于文本分类的方法<ul>
<li>针对单一事件类别<br><img src="/images/%E8%AF%9D%E9%A2%98%E5%8F%91%E7%8E%B0/2.png" alt="2"></li>
<li>人工特征提取针对性过强，泛化性，迁移性差，人为工作繁重，重复度高，引入人为干预，数据量少</li>
<li>针对多事件类别<br><img src="/images/%E8%AF%9D%E9%A2%98%E5%8F%91%E7%8E%B0/3.png" alt="3"> </li>
<li>各个事件类别相似度高，方法未实现更高程度的泛化性，无法统一利用数据，汇总数据进行学习</li>
</ul>
</li>
</ul>
</li>
<li>基于深度学习的亲历者发现<ul>
<li>使用词嵌入技术的亲历者发现<ul>
<li>使用词嵌入技术得到词向量，作为统计机器学习的输入特征之一</li>
</ul>
</li>
<li>使用神经网络模型的亲历者发现<ul>
<li>重点研究文本预处理对实验的影响，使用循环神经网络开展研究</li>
</ul>
</li>
<li>不足之处在于仍然采用统计机器学习方法，未引入端到端的深度学习模型设计思想，可解释性较差</li>
</ul>
</li>
<li>注意力机制<ul>
<li>增强可解释性<br><img src="/images/%E8%AF%9D%E9%A2%98%E5%8F%91%E7%8E%B0/4.png" alt="4"><br><img src="/images/%E8%AF%9D%E9%A2%98%E5%8F%91%E7%8E%B0/5.png" alt="5"></li>
</ul>
</li>
</ul>
<h1 id="拓展思路-1"><a href="#拓展思路-1" class="headerlink" title="拓展思路"></a>拓展思路</h1><ul>
<li>事件类别数量，事件数量，推文数量仍需扩充，多语种的或其他平台的数据</li>
<li><em>自动标注</em>的短板，人工标注的繁重</li>
<li>更复杂的模型设计，更先进的技术应用</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>CPSS</tag>
      </tags>
  </entry>
  <entry>
    <title>评论标签提取</title>
    <url>/2021/09/25/%E8%AF%84%E8%AE%BA%E6%A0%87%E7%AD%BE%E6%8F%90%E5%8F%96/</url>
    <content><![CDATA[<h1 id="评论文本的数据预处理"><a href="#评论文本的数据预处理" class="headerlink" title="评论文本的数据预处理"></a>评论文本的数据预处理</h1><p>对评论进行表示层的预处理，将评论从纯自然的中文形式，转换为模型适用的词、字符或向量形式。</p>
<span id="more"></span>

<p>清洗噪声之后，下一环节为中文分词</p>
<ul>
<li>词义消歧<ol>
<li>对于<em>一词多义</em>问题：采用Word2Vec中的most_similar函数对相似词进行替换处理，将多义词替换为语义层面相近的无歧义词。</li>
<li>对于<em>指代消解</em>问题：通过VSM(向量空间模型)和余弦相似度等进行处理。</li>
</ol>
</li>
<li>预定义词表</li>
</ul>
<p>针对罕见的地名或者演出形式，在分词过程中容易被拆分。</p>
<ul>
<li>未登录词</li>
</ul>
<p>指在已有全量评论语料中未出现的词，采用统一指代符号进行替换，解决词向量缺失问题。</p>
<ul>
<li>词性标注</li>
</ul>
<p>Jieba分词</p>
<ul>
<li>命名实体识别</li>
</ul>
<p>用在预定义词表的收集和确定上</p>
<ul>
<li>长句切分</li>
</ul>
<p>用于神经网络模型训练过程，删除“故事情节”部分，去标点符号，用空格代替</p>
<p><em>停用词</em></p>
<h3 id="功能词：表示指代或者功能-如：这；那里；在；的"><a href="#功能词：表示指代或者功能-如：这；那里；在；的" class="headerlink" title="功能词：表示指代或者功能 如：这；那里；在；的"></a>功能词：表示指代或者功能 如：这；那里；在；的</h3><h3 id="词汇词：如：想要；趁着；果然；什么"><a href="#词汇词：如：想要；趁着；果然；什么" class="headerlink" title="词汇词：如：想要；趁着；果然；什么"></a>词汇词：如：想要；趁着；果然；什么</h3><ul>
<li>语义层面的处理</li>
</ul>
<ol>
<li>Word2Vec 实质采用CBOW和Skip-Gram来训练词向量，CBOW输入为上下文词向量，输出为当前词向量。Skip-Gram输入是当前词向量，输出时上下文词向量，再通过霍夫曼编码以及一些列改进Softmax函数或者Negative Sampling的随机负采样来生成最终的词向量。  优点是训练速度快</li>
<li>GloVe考虑了词的共现情况，更能体现词义，进一步精准表示句子的语义</li>
<li>随机初始化词 随机一个<em>d</em>维向量</li>
</ol>
<h1 id="无监督的标签提取方法"><a href="#无监督的标签提取方法" class="headerlink" title="无监督的标签提取方法"></a>无监督的标签提取方法</h1><ul>
<li><p>广泛用于文章主题提取的LDA、基于TF-IDF的各类变种算法、基于统计机器翻译的新兴方法论</p>
</li>
<li><p>评论特点：随意性强，更新快，无规律</p>
</li>
<li><p>无法通过预先训练大量预料来对后续评论持续保持高效的抽取效果</p>
</li>
<li><p>TextRank作为主要的标签提取算法</p>
<p>​    <em>TextRank</em>是基于图网络的排序算法，将文本内容拆分成若干单元，每个单元由句子或单词组成，据此建立一个有向有权图【重要度得分公式】</p>
</li>
</ul>
<h1 id="基于深度学习的标签提取方法"><a href="#基于深度学习的标签提取方法" class="headerlink" title="基于深度学习的标签提取方法"></a>基于深度学习的标签提取方法</h1><ul>
<li>端到端的处理方式，极大地缩减了原来在特征工程及特征选择时间时的时间成本</li>
<li>CNN是一种有监督学习的神经网络方法</li>
<li>数据处理<ul>
<li>利用CNN对评论进行多分类，输入将被格式化为<em>文本</em>和<em>标注</em>两个文件，对应每一条评论和每一条评论的标签</li>
<li>评论是经过分词和去停用词处理过后的评论文本</li>
</ul>
</li>
<li>数据标注<ul>
<li>部分无法涌过关键词提取进行快速标注的数据，需要人工进行标注</li>
</ul>
</li>
<li>模型训练<ul>
<li>将标签看成多分类问题， 即将评论进行端到端的计算，输出为N个标签的概率，具体形式为N维向量，每一维度值为标签值及其对应的概率值，且最终会通过程序对N维向量进行排序，取TopK-作为最终输出的评论标签。</li>
</ul>
</li>
<li>将CNN的卷积操作当作N-Gram语言模型使用<pre><code>1. 每一层卷积操作之后，加一层MaxPooling，对每一层的特征进行择优取舍，增加特征的表达能力
 2. 将5层卷积+池化的结果进行基于concat的merge操作。Merge函数核心作用是对输出进行concat拼接，使得多层抽象出的特征向量可以组合成一个新的作为下一层的输入。
 3. 在下一层加入dropout，对经过5次卷积得到的拼接特征向量，进行不同程度的取舍，增加模型的泛化能力。
 4. 将模型输出通过Flatten函数打平，方便对卷积层出来的特征向量进行全连接操作。
</code></pre>
</li>
<li>模型优化<ul>
<li>单一标签模型Top5准确率比较低</li>
<li>考虑多模型融合的方式，将基于<strong>不同长度</strong>的N-Gram的模型分别训练，对最终的输出进行人工规则的方式进行错误纠正</li>
<li>强召回被标签模型忽略的标签，丢弃标签模型判错的标签</li>
<li>对TopK中K的选择，采用了K-means的方法，将N维标签概率值向量，进行K分类，实现动态TopK的标签提取</li>
<li>对于评论长度过短，但提取出的标签过多的情况，只取前2个标签作为最终标签输出。</li>
</ul>
</li>
</ul>
<h1 id="标签情感分析"><a href="#标签情感分析" class="headerlink" title="标签情感分析"></a>标签情感分析</h1><ul>
<li><p>实时性事件即与客观环境相关性不强，但与主体所处时间点的事件性内容强相关</p>
</li>
<li><p>对长短不一的内容抽取关键情感信息，从算法层面说，这类多标签情感信息重叠的情况可以归结为情感分析中的多标签正负样本杂糅的问题。</p>
</li>
<li><p>正负样本不均衡问题</p>
</li>
<li><p>TextCNN（<strong>解决绝大多数二分类问题</strong>）</p>
<ol>
<li>将完整评论用词向量表示</li>
<li>通过中文切词和词嵌入将完整评论转化为矩阵（具体长度会根据不同训练语料库而定，一般选定最大长度或平均长度）</li>
<li>将矩阵经过卷积核大小为2，3，4的三层卷积操作，对评论进行语义级别的特征抽取（根据评论的长度调整卷积核的数目）</li>
<li>池化操作，降维，通过拼接的方式，将特征向量拼接成新的特征向量</li>
<li>全连接和Softmax函数对模型进行输出，标签的总分类数即为最后Softmax的输出向量维度值</li>
</ol>
</li>
<li><p>TextRNN</p>
<ol>
<li>弥补了卷积神经网络中卷积核大小固定，导致卷积神经网络无法抽取到与当前词距离更长的词信息表达</li>
<li>更好地表达文本或语句上下文信息</li>
<li>将表示层词向量作为双向LSTM的输入，将输出进行拼接，进一步增加全连接和Softmax，最后得出概率值</li>
<li>双向LSTM结构，是将输入词向量的最后一维对应的输出直接作为预测分类的基准，节省训练时间</li>
</ol>
</li>
<li><p>CRNN</p>
<ol>
<li>CNN做文本特征抽取，RNN用于后续基于全局序列的情感分类</li>
<li>实现多卷积核的2D卷积操作，卷积后对输出进行非线性变换，采用ReLu函数，将卷积层输出的特征图压缩到隐变量h中，在maxpool操作后，仍然保持非线性特性，能够作为下一步lstm_cell的输入</li>
<li>在三分类和四分类问题上效果有显著提升</li>
</ol>
</li>
</ul>
]]></content>
      <tags>
        <tag>CPSS</tag>
      </tags>
  </entry>
  <entry>
    <title>Swin Transformer</title>
    <url>/2021/10/17/Swin_Transformer/</url>
    <content><![CDATA[<h2 id="Transformer从NLP迁移到CV上没有表现出特别好的效果的原因有以下两点"><a href="#Transformer从NLP迁移到CV上没有表现出特别好的效果的原因有以下两点" class="headerlink" title="Transformer从NLP迁移到CV上没有表现出特别好的效果的原因有以下两点"></a>Transformer从NLP迁移到CV上没有表现出特别好的效果的原因有以下两点</h2><ol>
<li>领域涉及的scale不同，NLP的scale是标准固定的，CV的scale变化范围很大</li>
<li>CV比NLP需要更大的分辨率，而且CV中使用Transformer的计算复杂度是图像尺寸的平方，会导致计算了过于庞大</li>
</ol>
<span id="more"></span>

<h2 id="相比于ViT，Swin-Transformer做出了一下改进"><a href="#相比于ViT，Swin-Transformer做出了一下改进" class="headerlink" title="相比于ViT，Swin Transformer做出了一下改进"></a>相比于ViT，Swin Transformer做出了一下改进</h2><ol>
<li>引入CNN中常用的层次化构建方式构建层次化Transformer</li>
<li>引入locality思想，对无重合的windows区域内进行self-attention计算</li>
<li>计算复杂度大幅度降低，具有输入图像大小线性计算复杂度</li>
<li>Swin Transformer随着深度加深，逐渐合并图像块来构建层次化Transformer，可以作为通用的视觉骨干网络应用于<em>图像分类，目标检测，语义分割</em>等任务</li>
</ol>
<p><img src="/images/Swin_Transformer/1.png" alt="1"></p>
<ol>
<li>架构和CNN架构非常类似，构建了4个stage，每个stage中都是类似的重复单元<ol>
<li>和ViT类似，通过patch partition将输入图片划分为不重合的patch集合，其中每个patch尺寸为4X4，每个patch的特征维度就变为4X4X3，patch块的数量为H/4 X W/4；stage1部分，先通过一个linear embedding将输入划分后的patch特征维度变成C，然后送入Swin Transformer Block；stage2-stage4操作相同。先通过一个<em>patch merging</em>，将输入按照2X2的相邻patch合并。</li>
</ol>
</li>
<li>划分patch的方式和ViT一样，先确定每个patch的大小，计算确定patch数量。随着网络深度的加深，patch数量会逐渐减少，并且每个patch的感知范围会扩大（ViT不变），能够适应视觉任务的多尺度。</li>
<li>进一步引入shifted window partition来解决不同window的信息交流问题</li>
</ol>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>CCF X BDCI 产品观点评论比赛</title>
    <url>/2021/10/24/%E8%AF%84%E8%AE%BA%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1 id="CCF-X-BDCI-产品观点评论比赛"><a href="#CCF-X-BDCI-产品观点评论比赛" class="headerlink" title="CCF X BDCI 产品观点评论比赛"></a>CCF X BDCI 产品观点评论比赛</h1><h2 id="BERT模型"><a href="#BERT模型" class="headerlink" title="BERT模型"></a>BERT模型</h2><p>BERT模型主要是针对word2vec等模型的不足，在之前的预训练模型（包括word2vec，ELMo等）都会生成词向量，这种类别的预训练模型属于domain transfer。而近一两年提出的ULMFiT，GPT，BERT等都属于模型迁移。BERT 模型是将预训练模型和下游任务模型结合在一起的，核心目的就是：是把下游具体NLP任务的活逐渐移到预训练产生词向量上。</p>
<span id="more"></span>

<h2 id="主要亮点"><a href="#主要亮点" class="headerlink" title="主要亮点"></a>主要亮点</h2><ol>
<li><p>双向Transformers</p>
<p><img src="/images/%E8%AF%84%E8%AE%BA%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/%E6%88%AA%E5%B1%8F2021-10-24%20%E4%B8%8B%E5%8D%882.48.45.png" alt="截屏2021-10-24 下午2.48.45"></p>
</li>
<li><p>句子级别的应用</p>
<p>通过使用segment同时考虑了句子级别的预测</p>
</li>
<li><p>根据不同的任务，按照BERT的输入要求输入我们的数据，获取输出，在输出层加一层全连接层。a，b都是sentence级别的：文本分类，关系抽取，c，d是tokens级别的：命名实体识别，知识问答等</p>
<center>

</center>

<p><img src="/images/%E8%AF%84%E8%AE%BA%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/%E6%88%AA%E5%B1%8F2021-10-24%20%E4%B8%8B%E5%8D%883.01.05.png" alt="截屏2021-10-24 下午3.01.05"></p>
</li>
</ol>
<h2 id="代码解读"><a href="#代码解读" class="headerlink" title="代码解读"></a>代码解读</h2><ol>
<li><p>预训练部分：run_pretraining.py</p>
</li>
<li><p>Fine-tune部分：</p>
<p>run_classifier.py：适用的任务为分类任务，如CoLA，MRPC，MultiNLI等</p>
<p>run_squad.py：适用的是阅读理解任务，如squad2.0和squad1.1</p>
</li>
<li><p>modeling.py：模型定义</p>
<p>optimization.py：优化器</p>
<p>tokenization.py：BasicTokenizer对原始句子内容的解析，进行unicode转换、标点符号分割、中文字符分割、去除重音符号等操作，最后返回关于词的数组，中文是字的数组WordpieceTokenizer的目的是将合成词分解成类似词根一样的词片。防止因为词的过于生僻没有被收录进词典最后只能以[UNK]代替的局面。FullTokenizer对一个文本段进行以上两种解析，最后返回词（字）的数组，同时提供token到id的索引以及id到token的索引。token可以理解为文本段处理过后的最小单元</p>
</li>
<li><p>需要修改的部分</p>
<ul>
<li><p>run_classifier.py</p>
<ul>
<li><p>BERT主要分为两部分，一个是训练语言模型的预训练部分，另一个是训练具体任务的fine-tune部分，在自己的数据集上进行fine-tune</p>
</li>
<li><p>InputExample类</p>
<p>主要定义了一些数据处理后要生成的字段名：</p>
<ul>
<li>guid：id号，一般将数据处理成train、dev、test数据集，定义方式可以是相应的数据集+行号（句子）</li>
<li>text_a：当前的句子</li>
<li>text_b：另一个句子</li>
<li>有些任务需要两个句子，如果任务中没有的话，可以讲text_b设为None</li>
<li>label：标签</li>
</ul>
</li>
<li><p>InputFeatures类</p>
<ul>
<li>定义了bert的输入格式，上面的格式是需要我们将原始数据处理成的格式，但并不是bert使用的最终格式，而且还会通过一些代码将InputExample转化为InputFeatures，这才是bert最终使用的数据格式，根据自己的需要可以定义一些字段作为中间辅助字段，但bert最基本的输入字段需要input_ids，input_mask和segment_ids这三个字段，label_id是计算loss时候用到的<ul>
<li>input_ids，segment_ids：分别对应单词id和句子(上下句标示)</li>
<li>input_ids、segment_ids分别代表token、segment</li>
<li>input_mask：记录的是填充信息</li>
</ul>
</li>
</ul>
</li>
<li><p>DataProcessor</p>
<ul>
<li>数据预处理的基类</li>
<li>tokenization中的convert_to_unicode就是将文本转化为utf-8编码</li>
<li>数据预处理过程，需要我们根据自己的数据定义，但是并不是bert使用的最终样子，还得经过一系列过程才能变成其能处理的数据格式：<ul>
<li>convert_single_example：返回一个InputFeatures类</li>
<li>file_based_convert_example_to_features</li>
<li>file_based_input_fn_builder</li>
<li>truncate_seq_pair</li>
</ul>
</li>
</ul>
</li>
<li><p>convert_single_example</p>
<ul>
<li>bert输入<img src="/images/%E8%AF%84%E8%AE%BA%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/%E6%88%AA%E5%B1%8F2021-10-24%20%E4%B8%8B%E5%8D%884.21.36.png" alt="截屏2021-10-24 下午4.21.36"></li>
<li>input_ids：记录的是使用FullTokenizer类convert_tokens_to_ids方法将tokens转化成单个字的id</li>
<li>segment_ids：句子级别（上下句）的标签</li>
<li>input_mask：和最大长度有关，假设我们定义句子的最大长度是120，当前句子长度是100，那么input_mask前100个元素都是1，其余20个就是0</li>
</ul>
</li>
</ul>
</li>
<li><p>run_squad.py</p>
</li>
</ul>
</li>
<li><p>模型部分</p>
<ul>
<li><p>create_model</p>
<ul>
<li>bert模型的输入：input_ids，input_mask，segment_ids</li>
<li>bert模型的输出：<ul>
<li>model.get_sequence_output（）：第一种输出结果是[batch_size, seq_length, embedding_size]</li>
<li>model.get_pooled_output()：第二种输出结果是[batch_size, embedding_size]</li>
<li>第二种结果是第一种结果在第二个维度上进行了池化，第一种得到的是tokens级别的结果，第二种是句子级别的</li>
<li><strong>使用bert进行任务时，主要变的就是这个部分</strong></li>
</ul>
</li>
</ul>
</li>
<li><p>model_fn_builder</p>
<p>首先调用create_model得到total_loss、 per_example_loss、logits、 probabilities等，然后针对不同的状态返回不同的结果（output_spec）:</p>
<ul>
<li>如果是train，返回loss、train_op</li>
<li>如果是dev，返回评价指标，比如accuracy</li>
<li>如果是test，返回预测结果</li>
<li>如果想看其他指标，可以在这边修改，因为使用了estimator API，使得其必须返回一个operation</li>
<li>F1-score定义：<a href="https://www.cnblogs.com/jiangxinyang/p/10341392.html">https://www.cnblogs.com/jiangxinyang/p/10341392.html</a></li>
</ul>
</li>
</ul>
</li>
<li><p>main函数</p>
<p>定义预处理器，把自己定义的预处理包含进去，处理完使用tf.contrib.tpu.TPUEstimator定义模型，最后根据不同模式运行estimator.train，estimator.evaluate，estimator.predict</p>
</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在进行任务时，复制BERT的run_classifier.py，修改核心内容作为自己的run函数，包括继承DataProcessor，定义一个自己的数据预处理类，在create_model中，定义自己的具体下游工作</p>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
</search>
